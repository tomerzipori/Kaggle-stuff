rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)")# |>
col_vec <- c("#e63946", "#f1faee", "#a8dadc", "black")
coefs |>
# preparing df for plot
rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)") |>
mutate(bigger_then_0 = Coefficient > 0) |>
# ggplotting
ggplot(aes(x = Token, y = Coefficient, fill = bigger_then_0)) +
geom_point() +
scale_y_continuous(n.breaks = 10) +
ggtitle("Most important words for classifying if a tweet is fake news") +
theme_classic() +
geom_hline(yintercept = 0, color = "#51087E", linetype = 2, size = 1, show.legend = F) +
theme(plot.background = element_rect(color = col_vec[2], fill = col_vec[2]),
panel.background = element_rect(color = col_vec[2], fill = col_vec[2]),
axis.line = element_line(color = col_vec[4]),
axis.title = element_text(color = col_vec[4]),
axis.text = element_text(color = col_vec[4]),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12, face = "bold"),
plot.title = element_text(size = 16, color = col_vec[4], hjust = .5, family = "serif", face = "bold"))
coefs |>
# preparing df for plot
rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)") |>
mutate(bigger_then_0 = Coefficient > 0) |>
# ggplotting
ggplot(aes(x = Token, y = Coefficient, color = bigger_then_0)) +
geom_point() +
scale_y_continuous(n.breaks = 10) +
ggtitle("Most important words for classifying if a tweet is fake news") +
theme_classic() +
geom_hline(yintercept = 0, color = "#51087E", linetype = 2, size = 1, show.legend = F) +
theme(plot.background = element_rect(color = col_vec[2], fill = col_vec[2]),
panel.background = element_rect(color = col_vec[2], fill = col_vec[2]),
axis.line = element_line(color = col_vec[4]),
axis.title = element_text(color = col_vec[4]),
axis.text = element_text(color = col_vec[4]),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12, face = "bold"),
plot.title = element_text(size = 16, color = col_vec[4], hjust = .5, family = "serif", face = "bold"))
coefs |>
# preparing df for plot
rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)") |>
mutate(bigger_then_0 = Coefficient > 0) |>
# ggplotting
ggplot(aes(x = Token, y = Coefficient, color = bigger_then_0)) +
geom_point() +
scale_color_manual(values = c(col_vec[1], col_vec[2])) +
scale_y_continuous(n.breaks = 10) +
ggtitle("Most important words for classifying if a tweet is fake news") +
theme_classic() +
geom_hline(yintercept = 0, color = "#51087E", linetype = 2, size = 1, show.legend = F) +
theme(plot.background = element_rect(color = col_vec[2], fill = col_vec[2]),
panel.background = element_rect(color = col_vec[2], fill = col_vec[2]),
axis.line = element_line(color = col_vec[4]),
axis.title = element_text(color = col_vec[4]),
axis.text = element_text(color = col_vec[4]),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12, face = "bold"),
plot.title = element_text(size = 16, color = col_vec[4], hjust = .5, family = "serif", face = "bold"))
coefs |>
# preparing df for plot
rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)") |>
mutate(bigger_then_0 = Coefficient > 0) |>
# ggplotting
ggplot(aes(x = Token, y = Coefficient, color = bigger_then_0)) +
geom_point() +
scale_color_manual(values = c(col_vec[3], col_vec[1])) +
scale_y_continuous(n.breaks = 10) +
ggtitle("Most important words for classifying if a tweet is fake news") +
theme_classic() +
geom_hline(yintercept = 0, color = "#51087E", linetype = 2, size = 1, show.legend = F) +
theme(plot.background = element_rect(color = col_vec[2], fill = col_vec[2]),
panel.background = element_rect(color = col_vec[2], fill = col_vec[2]),
axis.line = element_line(color = col_vec[4]),
axis.title = element_text(color = col_vec[4]),
axis.text = element_text(color = col_vec[4]),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12, face = "bold"),
plot.title = element_text(size = 16, color = col_vec[4], hjust = .5, family = "serif", face = "bold"))
coefs |>
# preparing df for plot
rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)") |>
mutate(bigger_then_0 = Coefficient > 0) |>
# ggplotting
ggplot(aes(x = Token, y = Coefficient, color = bigger_then_0)) +
geom_point() +
scale_color_manual(values = c(col_vec[1], col_vec[3])) +
scale_y_continuous(n.breaks = 10) +
ggtitle("Most important words for classifying if a tweet is fake news") +
theme_classic() +
geom_hline(yintercept = 0, color = "#51087E", linetype = 2, size = 1, show.legend = F) +
theme(plot.background = element_rect(color = col_vec[2], fill = col_vec[2]),
panel.background = element_rect(color = col_vec[2], fill = col_vec[2]),
axis.line = element_line(color = col_vec[4]),
axis.title = element_text(color = col_vec[4]),
axis.text = element_text(color = col_vec[4]),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12, face = "bold"),
legend.position = "none",
plot.title = element_text(size = 16, color = col_vec[4], hjust = .5, family = "serif", face = "bold"))
#| out-width: 200%
lr_summary <- summary(lr_model) # summarizing the model
coefs <- data.frame(lr_summary$estimated.feature.scores) # extracting coefficients
col_vec <- c("#fc7753", "#f2efea", "#66d7d1", "black")
coefs |>
# preparing df for plot
rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)") |>
mutate(bigger_then_0 = Coefficient > 0) |>
# ggplotting
ggplot(aes(x = Token, y = Coefficient, color = bigger_then_0)) +
geom_point() +
scale_color_manual(values = c(col_vec[1], col_vec[3])) +
scale_y_continuous(n.breaks = 10) +
ggtitle("Most important words for classifying if a tweet is fake news") +
theme_classic() +
geom_hline(yintercept = 0, color = "#51087E", linetype = 2, size = 1, show.legend = F) +
theme(plot.background = element_rect(color = col_vec[2], fill = col_vec[2]),
panel.background = element_rect(color = col_vec[2], fill = col_vec[2]),
axis.line = element_line(color = col_vec[4]),
axis.title = element_text(color = col_vec[4]),
axis.text = element_text(color = col_vec[4]),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12, face = "bold"),
legend.position = "none",
plot.title = element_text(size = 16, color = col_vec[4], hjust = .5, family = "serif", face = "bold"))
coefs |>
# preparing df for plot
rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)") |>
mutate(bigger_then_0 = Coefficient > 0) |>
# ggplotting
ggplot(aes(x = Token, y = Coefficient, color = bigger_then_0)) +
geom_point() +
scale_color_manual(values = c(col_vec[1], col_vec[3])) +
scale_y_continuous(n.breaks = 10) +
labs(title = "Most important words for classifying if a tweet is fake news",
x = "") +
theme_classic() +
geom_hline(yintercept = 0, color = "#51087E", linetype = 2, size = 1, show.legend = F) +
theme(plot.background = element_rect(color = col_vec[2], fill = col_vec[2]),
panel.background = element_rect(color = col_vec[2], fill = col_vec[2]),
axis.line = element_line(color = col_vec[4]),
axis.title = element_text(color = col_vec[4]),
axis.text = element_text(color = col_vec[4]),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12, face = "bold"),
legend.position = "none",
plot.title = element_text(size = 16, color = col_vec[4], hjust = .5, family = "serif", face = "bold"))
#| output: false
library(tidyverse)
library(quanteda)
library(topicmodels)
library(quanteda.textmodels)
library(spacyr)
library(corpustools)
library(glue)
real <- read_csv("real.csv", show_col_types = F)
fake <- read_csv("fake.csv", show_col_types = F)
real$label <- "real"
fake$label <- "fake"
tweets <- rbind(real, fake) |>
drop_na() |> # dropping NA rows
mutate(tweet = str_trim(tweet) |> str_squish()) # removing white-spaces in the start and beginning of tweet, and between words
corp <- corpus(tweets, text_field = "tweet")
data_feature_mat <- corp |>
tokens(remove_punct = T, remove_numbers = T, remove_url = T, remove_separators = T, remove_symbols = T) |>
tokens_wordstem() |>
dfm(tolower = T) |>
dfm_tfidf()
set.seed(14)
train_data <- dfm_sample(data_feature_mat, size = 0.8 * nrow(data_feature_mat))
test_data <- data_feature_mat[setdiff(docnames(data_feature_mat), docnames(train_data)),]
nb_model <- textmodel_nb(train_data, y = docvars(train_data, "label"))
pred_nb <- predict(nb_model, newdata = test_data)
(conmat_nb <- table(pred_nb, docvars(test_data, "label")))
caret::confusionMatrix(conmat_nb, mode = "everything", positive = "real")
lr_model <- textmodel_lr(x = train_data, y = docvars(train_data, "label"))
pred_lr <- predict(lr_model, newdata = test_data)
(conmat_lt <- table(pred_lr, docvars(test_data, "label")))
caret::confusionMatrix(conmat_lt, mode = "everything", positive = "real")
#| out-width: 200%
#| code-fold: true
lr_summary <- summary(lr_model) # summarizing the model
coefs <- data.frame(lr_summary$estimated.feature.scores) # extracting coefficients
col_vec <- c("#fc7753", "#f2efea", "#66d7d1", "black")
coefs |>
# preparing df for plot
rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)") |>
mutate(bigger_then_0 = Coefficient > 0) |>
# ggplotting
ggplot(aes(x = Token, y = Coefficient, color = bigger_then_0)) +
geom_point() +
scale_color_manual(values = c(col_vec[1], col_vec[3])) +
scale_y_continuous(n.breaks = 10) +
labs(title = "Most important words for classifying if a tweet is fake news",
x = "") +
theme_classic() +
geom_hline(yintercept = 0, color = "black", linetype = 2, size = 1, show.legend = F) +
theme(plot.background = element_rect(color = col_vec[2], fill = col_vec[2]),
panel.background = element_rect(color = col_vec[2], fill = col_vec[2]),
axis.line = element_line(color = col_vec[4]),
axis.title = element_text(color = col_vec[4]),
axis.text = element_text(color = col_vec[4]),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12, face = "bold"),
legend.position = "none",
plot.title = element_text(size = 16, color = col_vec[4], hjust = .5, family = "serif", face = "bold"))
#| output: false
library(tidyverse)
library(quanteda)
library(topicmodels)
library(quanteda.textmodels)
library(spacyr)
library(corpustools)
library(glue)
real <- read_csv("real.csv", show_col_types = F)
fake <- read_csv("fake.csv", show_col_types = F)
real$label <- "real"
fake$label <- "fake"
tweets <- rbind(real, fake) |>
drop_na() |> # dropping NA rows
mutate(tweet = str_trim(tweet) |> str_squish()) # removing white-spaces in the start and beginning of tweet, and between words
corp <- corpus(tweets, text_field = "tweet")
data_feature_mat <- corp |>
tokens(remove_punct = T, remove_numbers = T, remove_url = T, remove_separators = T, remove_symbols = T) |>
tokens_wordstem() |>
dfm(tolower = T) |>
dfm_tfidf()
set.seed(14)
train_data <- dfm_sample(data_feature_mat, size = 0.8 * nrow(data_feature_mat))
test_data <- data_feature_mat[setdiff(docnames(data_feature_mat), docnames(train_data)),]
nb_model <- textmodel_nb(train_data, y = docvars(train_data, "label"))
pred_nb <- predict(nb_model, newdata = test_data)
(conmat_nb <- table(pred_nb, docvars(test_data, "label")))
caret::confusionMatrix(conmat_nb, mode = "everything", positive = "real")
lr_model <- textmodel_lr(x = train_data, y = docvars(train_data, "label"))
pred_lr <- predict(lr_model, newdata = test_data)
(conmat_lr <- table(pred_lr, docvars(test_data, "label")))
caret::confusionMatrix(conmat_lr, mode = "everything", positive = "real")
#| out-width: 200%
#| code-fold: true
lr_summary <- summary(lr_model) # summarizing the model
coefs <- data.frame(lr_summary$estimated.feature.scores) # extracting coefficients
col_vec <- c("#fc7753", "#f2efea", "#66d7d1", "black")
coefs |>
# preparing df for plot
rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)") |>
mutate(bigger_then_0 = Coefficient > 0) |>
# ggplotting
ggplot(aes(x = Token, y = Coefficient, color = bigger_then_0)) +
geom_point() +
scale_color_manual(values = c(col_vec[1], col_vec[3])) +
scale_y_continuous(n.breaks = 10) +
labs(title = "Most important words for classifying if a tweet is fake news",
x = "") +
theme_classic() +
geom_hline(yintercept = 0, color = "black", linetype = 2, linewidth = 1, show.legend = F) +
theme(plot.background = element_rect(color = col_vec[2], fill = col_vec[2]),
panel.background = element_rect(color = col_vec[2], fill = col_vec[2]),
axis.line = element_line(color = col_vec[4]),
axis.title = element_text(color = col_vec[4]),
axis.text = element_text(color = col_vec[4]),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12, face = "bold"),
legend.position = "none",
plot.title = element_text(size = 16, color = col_vec[4], hjust = .5, family = "serif", face = "bold"))
corp
corp[1]
corp[c(1,41,44,2)]
sample(corp, 1)
length(corp)
length(corp)*0.8
train_data <- sample(corp, floor(0.8 * length(corp)), replace = T)
train_data[1]
train_data[2]
train_data[19]
corp[1]
corp[2]
train_data[1]
corp[34782]
names(train_data)[1]
names(train_data)[1:10]
?sample
train_data <- sample(corp, floor(0.8 * length(corp)), replace = F)
names(train_data)[1:10]
train_data
test_data <- corp[!(corp %in% train_data)]
0.2*length(corp)
test_data <- corp[!(names(corp) %in% names(train_data))]
set.seed(14)
train_data <- sample(corp, floor(0.8 * length(corp)), replace = F)
test_data <- corp[!(names(corp) %in% names(train_data))]
train_dfm <- train_data |>
tokens(remove_punct = T, remove_numbers = T, remove_url = T, remove_separators = T, remove_symbols = T) |>
tokens_wordstem() |>
dfm(tolower = T) |>
dfm_tfidf()
test_dfm <- test_data |>
tokens(remove_punct = T, remove_numbers = T, remove_url = T, remove_separators = T, remove_symbols = T) |>
tokens_wordstem() |>
dfm(tolower = T) |>
dfm_tfidf()
nb_model <- textmodel_nb(train_dfm, y = docvars(train_dfm, "label"))
pred_nb <- predict(nb_model, newdata = test_dfm)
pred_nb <- predict(nb_model, newdata = test_data)
pred_nb <- predict(nb_model, newdata = test_dfm)
docvars(test_data)
docvars(test_data)[1]
head(docvars(test_data))
corp
docvars(corp)
docvars(train_data)
summary(docvars(train_data))
table(docvars(train_data))
table(docvars(test_data))
train_dfm <- train_data |>
tokens(remove_punct = T, remove_numbers = T, remove_url = T, remove_separators = T, remove_symbols = T) |>
tokens_wordstem() |>
dfm(tolower = T) |>
dfm_tfidf()
test_dfm <- test_data |>
tokens(remove_punct = T, remove_numbers = T, remove_url = T, remove_separators = T, remove_symbols = T) |>
tokens_wordstem() |>
dfm(tolower = T) |>
dfm_tfidf()
nb_model <- textmodel_nb(train_dfm, y = docvars(train_dfm, "label"))
pred_nb <- predict(nb_model, newdata = test_dfm)
data_feature_mat <- corp |>
tokens(remove_punct = T, remove_numbers = T, remove_url = T, remove_separators = T, remove_symbols = T) |>
tokens_wordstem() |>
dfm(tolower = T)
nrow(data_feature_mat)
train_dfm <- dfm_sample(data_feature_mat, size = 0.8 * nrow(data_feature_mat))
test_dfm <- data_feature_mat[setdiff(docnames(data_feature_mat), docnames(train_dfm)),]
nb_model <- textmodel_nb(train_dfm, y = docvars(train_dfm, "label"))
pred_nb <- predict(nb_model, newdata = test_dfm)
(conmat_nb <- table(pred_nb, docvars(test_dfm, "label")))
caret::confusionMatrix(conmat_nb, mode = "everything", positive = "real")
set.seed(14)
train_dfm <- dfm_sample(data_feature_mat, size = 0.8 * nrow(data_feature_mat))
test_dfm <- data_feature_mat[setdiff(docnames(data_feature_mat), docnames(train_dfm)),]
nb_model <- textmodel_nb(train_dfm, y = docvars(train_dfm, "label"))
pred_nb <- predict(nb_model, newdata = test_dfm)
(conmat_nb <- table(pred_nb, docvars(test_dfm, "label")))
caret::confusionMatrix(conmat_nb, mode = "everything", positive = "real")
lr_model <- textmodel_lr(x = train_dfm, y = docvars(train_data, "label"))
pred_lr <- predict(lr_model, newdata = test_dfm)
(conmat_lr <- table(pred_lr, docvars(test_dfm, "label")))
caret::confusionMatrix(conmat_lr, mode = "everything", positive = "real")
#| out-width: 200%
#| code-fold: true
lr_summary <- summary(lr_model) # summarizing the model
coefs <- data.frame(lr_summary$estimated.feature.scores) # extracting coefficients
col_vec <- c("#fc7753", "#f2efea", "#66d7d1", "black")
coefs |>
# preparing df for plot
rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)") |>
mutate(bigger_then_0 = Coefficient > 0) |>
# ggplotting
ggplot(aes(x = Token, y = Coefficient, color = bigger_then_0)) +
geom_point() +
scale_color_manual(values = c(col_vec[1], col_vec[3])) +
scale_y_continuous(n.breaks = 10) +
labs(title = "Most important words for classifying if a tweet is fake news",
x = "") +
theme_classic() +
geom_hline(yintercept = 0, color = "black", linetype = 2, linewidth = 1, show.legend = F) +
theme(plot.background = element_rect(color = col_vec[2], fill = col_vec[2]),
panel.background = element_rect(color = col_vec[2], fill = col_vec[2]),
axis.line = element_line(color = col_vec[4]),
axis.title = element_text(color = col_vec[4]),
axis.text = element_text(color = col_vec[4]),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12, face = "bold"),
legend.position = "none",
plot.title = element_text(size = 16, color = col_vec[4], hjust = .5, family = "serif", face = "bold"))
#| output: false
library(tidyverse)
library(quanteda)
library(topicmodels)
library(quanteda.textmodels)
library(spacyr)
library(corpustools)
library(glue)
real <- read_csv("real.csv", show_col_types = F)
fake <- read_csv("fake.csv", show_col_types = F)
real$label <- "real"
fake$label <- "fake"
tweets <- rbind(real, fake) |>
drop_na() |> # dropping NA rows
mutate(tweet = str_trim(tweet) |> str_squish()) # removing white-spaces in the start and beginning of tweet, and between words
corp <- corpus(tweets, text_field = "tweet")
data_feature_mat <- corp |>
tokens(remove_punct = T, remove_numbers = T, remove_url = T, remove_separators = T, remove_symbols = T) |>
tokens_wordstem() |>
dfm(tolower = T)
set.seed(14)
train_dfm <- dfm_sample(data_feature_mat, size = 0.8 * nrow(data_feature_mat))
test_dfm <- data_feature_mat[setdiff(docnames(data_feature_mat), docnames(train_dfm)),]
nb_model <- textmodel_nb(train_dfm, y = docvars(train_dfm, "label"))
pred_nb <- predict(nb_model, newdata = test_dfm)
(conmat_nb <- table(pred_nb, docvars(test_dfm, "label")))
caret::confusionMatrix(conmat_nb, mode = "everything", positive = "real")
lr_model <- textmodel_lr(x = train_dfm, y = docvars(train_data, "label"))
#| output: false
library(tidyverse)
library(quanteda)
library(topicmodels)
library(quanteda.textmodels)
library(spacyr)
library(corpustools)
library(glue)
real <- read_csv("real.csv", show_col_types = F)
fake <- read_csv("fake.csv", show_col_types = F)
real$label <- "real"
fake$label <- "fake"
tweets <- rbind(real, fake) |>
drop_na() |> # dropping NA rows
mutate(tweet = str_trim(tweet) |> str_squish()) # removing white-spaces in the start and beginning of tweet, and between words
corp <- corpus(tweets, text_field = "tweet")
data_feature_mat <- corp |>
tokens(remove_punct = T, remove_numbers = T, remove_url = T, remove_separators = T, remove_symbols = T) |>
tokens_wordstem() |>
dfm(tolower = T)
set.seed(14)
train_dfm <- dfm_sample(data_feature_mat, size = 0.8 * nrow(data_feature_mat))
test_dfm <- data_feature_mat[setdiff(docnames(data_feature_mat), docnames(train_dfm)),]
nb_model <- textmodel_nb(train_dfm, y = docvars(train_dfm, "label"))
pred_nb <- predict(nb_model, newdata = test_dfm)
(conmat_nb <- table(pred_nb, docvars(test_dfm, "label")))
caret::confusionMatrix(conmat_nb, mode = "everything", positive = "real")
lr_model <- textmodel_lr(x = train_dfm, y = docvars(train_data, "label"))
head(corp)
head(data_feature_mat)
table(docvars(data_feature_mat, 'label'))['real'])
table(docvars(data_feature_mat, 'label'))['real']
table(docvars(data_feature_mat, 'label'))['fake']
pred_lr <- predict(lr_model, newdata = test_dfm)
#| output: false
library(tidyverse)           # data loading, data preparation and stringr
library(quanteda)            # text preprocessing and DFM creation
library(quanteda.textmodels) # machine learning models
library(glue)                # that's a secret
real <- read_csv("real.csv", show_col_types = F)
fake <- read_csv("fake.csv", show_col_types = F)
real$label <- "real"
fake$label <- "fake"
tweets <- rbind(real, fake) |>
drop_na() |> # dropping NA rows
mutate(tweet = str_trim(tweet) |> str_squish()) # removing white-spaces in the start and beginning of tweet, and between words
corp <- corpus(tweets, text_field = "tweet")
head(corp)
data_feature_mat <- corp |>
tokens(remove_punct = T, remove_numbers = T, remove_url = T, remove_separators = T, remove_symbols = T) |>
tokens_wordstem() |>
dfm(tolower = T)
head(data_feature_mat)
table(docvars(data_feature_mat, 'label'))['real']
table(docvars(data_feature_mat, 'label'))['fake']
#| echo: false
base_rate <- glue("${round(table(docvars(data_feature_mat, 'label'))['real']/(table(docvars(data_feature_mat, 'label'))['fake']+table(docvars(data_feature_mat, 'label'))['real']), 3)}$")
set.seed(14)
train_dfm <- dfm_sample(data_feature_mat, size = 0.8 * nrow(data_feature_mat)) # large sample, we can use 80-20 train-test split
test_dfm <- data_feature_mat[setdiff(docnames(data_feature_mat), docnames(train_dfm)),]
nb_model <- textmodel_nb(train_dfm, y = docvars(train_dfm, "label"))
pred_nb <- predict(nb_model, newdata = test_dfm)
(conmat_nb <- table(pred_nb, docvars(test_dfm, "label")))
caret::confusionMatrix(conmat_nb, mode = "everything", positive = "real")
lr_model <- textmodel_lr(x = train_dfm, y = docvars(train_dfm, "label"))
pred_lr <- predict(lr_model, newdata = test_dfm)
(conmat_lr <- table(pred_lr, docvars(test_dfm, "label")))
caret::confusionMatrix(conmat_lr, mode = "everything", positive = "real")
#| out-width: 200%
#| code-fold: true
lr_summary <- summary(lr_model) # summarizing the model
coefs <- data.frame(lr_summary$estimated.feature.scores) # extracting coefficients
col_vec <- c("#fc7753", "#f2efea", "#66d7d1", "black")
coefs |>
# preparing df for plot
rownames_to_column(var = "Token") |>
rename(Coefficient = real) |>
filter(Coefficient != 0 & Token != "(Intercept)") |>
mutate(bigger_then_0 = Coefficient > 0) |>
# ggplotting
ggplot(aes(x = Token, y = Coefficient, color = bigger_then_0)) +
geom_point() +
scale_color_manual(values = c(col_vec[1], col_vec[3])) +
scale_y_continuous(n.breaks = 10) +
labs(title = "Most important words for classifying if a tweet is fake news",
x = "") +
theme_classic() +
geom_hline(yintercept = 0, color = "black", linetype = 2, linewidth = 1, show.legend = F) +
theme(plot.background = element_rect(color = col_vec[2], fill = col_vec[2]),
panel.background = element_rect(color = col_vec[2], fill = col_vec[2]),
axis.line = element_line(color = col_vec[4]),
axis.title = element_text(color = col_vec[4]),
axis.text = element_text(color = col_vec[4]),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12, face = "bold"),
legend.position = "none",
plot.title = element_text(size = 16, color = col_vec[4], hjust = .5, family = "serif", face = "bold"))
